# Deep Q-Learning no Ambiente Taxi-v3

Este projeto implementa um agente de **Reinforcement Learning** utilizando a abordagem **Deep Q-Learning (DQN)** no ambiente **Taxi-v3** do Gymnasium. O c√≥digo foi desenvolvido e testado no **Google Colab**, aproveitando os recursos da plataforma para realizar simula√ß√µes e visualiza√ß√µes de forma eficiente.

---

## üìñ **Descri√ß√£o do Projeto**

O objetivo do agente √© aprender a realizar a tarefa de transporte de passageiros no ambiente **Taxi-v3** de maneira otimizada. Para isso, ele utiliza o algoritmo **Deep Q-Learning**, que combina:

- **Rede Neural Profunda (DQN)**: Para aproximar os valores-Q.
- **Replay Buffer**: Para armazenar e reutilizar transi√ß√µes da experi√™ncia passada.
- **Target Network**: Para estabilidade no treinamento.

### **Principais Funcionalidades**
- Treinamento do agente em um ambiente discreto com estados representados por *one-hot encoding*.
- Visualiza√ß√£o do desempenho do agente por meio de gr√°ficos.
- Cria√ß√£o de um GIF animado mostrando as a√ß√µes do agente no ambiente ap√≥s o treinamento.

---

## üõ†Ô∏è **Desenvolvimento no Google Colab**

O c√≥digo foi inteiramente testado no ambiente **Google Colab**, que oferece uma configura√ß√£o r√°pida e pr√°tica para projetos em Python. O Colab permite:

- Instala√ß√£o de depend√™ncias como `gymnasium`, `pygame` e `moviepy`.
- Renderiza√ß√£o de frames e gera√ß√£o de anima√ß√µes para visualiza√ß√£o do aprendizado do agente.
- Visualiza√ß√£o de gr√°ficos e m√©tricas durante o treinamento.

### **Passos Realizados**
1. **Configura√ß√£o Inicial**:
   - Instala√ß√£o de pacotes necess√°rios:
     ```bash
     !apt-get install -y python-opengl ffmpeg > /dev/null
     !pip install gymnasium moviepy pygame > /dev/null
     ```
   - Prepara√ß√£o do ambiente **Taxi-v3** no Gymnasium.

2. **Treinamento**:
   - O agente foi treinado por 500 epis√≥dios, ajustando sua pol√≠tica para maximizar as recompensas.
   - Utilizou-se uma rede neural simples com duas camadas ocultas para aproximar os Q-values.

3. **Visualiza√ß√£o**:
   - Quadros renderizados foram coletados e transformados em GIF para acompanhar o comportamento do agente.
   - Um gr√°fico de desempenho (recompensa por epis√≥dio) foi gerado.

---

## üìä **Resultados Obtidos**

1. **Gr√°fico de Recompensas**:
   - Mostra a evolu√ß√£o do desempenho do agente ao longo dos epis√≥dios de treinamento.
   - O agente aprendeu a maximizar a recompensa acumulada com o tempo.

2. **GIF Animado**:
   - O GIF gerado (`images/dqn_training_visualization.gif`) demonstra as decis√µes tomadas pelo agente em um ambiente vis√≠vel.

---

## üöÄ **Como Executar no Colab**

1. Copie o c√≥digo fornecido em um notebook do Google Colab.
2. Certifique-se de instalar todas as depend√™ncias.
3. Execute o treinamento e visualize os resultados diretamente na plataforma.
4. link colab: https://colab.research.google.com/drive/1pzJUex68u-_YT7OjJwEhNnshkN-gVnbc?authuser=1#scrollTo=hs7ZjW_dZD2T

---

